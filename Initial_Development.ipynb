{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Initial_Development.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiXr-_R-uoqG",
        "colab_type": "text"
      },
      "source": [
        "# Initial Development for CIFAR-10 Image Classification using GUNN-15\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy1lXneGf8lL",
        "colab_type": "code",
        "outputId": "06551430-73fd-463d-e257-bd5addeab96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "#!pip install tensorflow==1.14.0\n",
        "!pip install -U keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU0nhShL_om5",
        "colab_type": "code",
        "outputId": "278a7617-8a24-426d-9a8c-73df6e19eae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers.core import Lambda\n",
        "from keras import regularizers\n",
        "from keras.models import Model, Sequential\n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "#from kt_utils import *\n",
        "#from keras.backend import tf\n",
        "from keras.layers import Lambda\n",
        "import tensorflow as tf\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57zcVlj1kf8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh5VXIfik9x-",
        "colab_type": "code",
        "outputId": "38bde437-80df-48c5-a495-261c1b81b3cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "(X_train_orig, Y_train_orig), (X_test_orig, Y_test_orig) = cifar10.load_data()\n",
        "X_train_orig = X_train_orig.astype('float32')\n",
        "X_test_orig = X_test_orig.astype('float32')\n",
        "\n",
        "# Normalize image vectors\n",
        "mean = np.mean(X_train_orig,axis=(0,1,2,3))\n",
        "std = np.std(X_train_orig, axis=(0, 1, 2, 3))\n",
        "X_train = (X_train_orig-mean)/(std+1e-7)\n",
        "X_test = (X_test_orig-mean)/(std+1e-7)\n",
        "#X_train = X_train_orig/255.\n",
        "#X_test = X_test_orig/255.\n",
        "\n",
        "Y_train = keras.utils.to_categorical(Y_train_orig, 10)\n",
        "Y_test = keras.utils.to_categorical(Y_test_orig, 10)\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "number of training examples = 50000\n",
            "number of test examples = 10000\n",
            "X_train shape: (50000, 32, 32, 3)\n",
            "Y_train shape: (50000, 10)\n",
            "X_test shape: (10000, 32, 32, 3)\n",
            "Y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Heve0E8uCas-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Gunn2D_Backup(X, input_channels, expansion_rate):\n",
        "    \"\"\"\n",
        "    Implementation of the Gunn2D layer as defined in the paper\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    input_channels -- integer, defining the number of input filters \n",
        "    expansion_rate -- integer, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the Gunn2D layer, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    output_channels = input_channels / expansion_rate\n",
        "    \n",
        "    for i in range(1, expansion_rate+1):\n",
        "      X_shortcut = X\n",
        "      print(X)\n",
        "      X = Conv2D(output_channels*2, (1, 1), strides = (1, 1), padding='valid', name = 'g1'+str(i))(X)\n",
        "      print(X)\n",
        "      X = BatchNormalization(axis = 3 , name = 'bn5')(X)\n",
        "      X = Activation('relu')(X)\n",
        "      X = Conv2D(output_channels*2, (3, 3), strides = (1, 1), padding='same', name = 'g2'+str(i))(X)\n",
        "      X = BatchNormalization(axis = 3 , name = 'bn6')(X)\n",
        "      X = Activation('relu')(X)\n",
        "      X = Conv2D(output_channels, (1, 1), strides = (1, 1), padding='valid', name = 'g3'+str(i))(X)\n",
        "      X = BatchNormalization(axis = 3 , name = 'bn7')(X)\n",
        "      print(X)\n",
        "      #Implementation of the identity block in Residual Network\n",
        "      X_shortcut = Conv2D(output_channels, (1, 1), strides = (1, 1), padding='valid', name = 'g1'+str(i))(X)\n",
        "      X_shortcut = BatchNormalization(axis = 3 , name = 'bn5')(X)\n",
        "      X = Add()([X , X_shortcut])\n",
        "\n",
        "    return X\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tV2nmzcwcso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Gunn2D_back2(X, input_channels, expansion_rate):\n",
        "    \"\"\"\n",
        "    Implementation of the Gunn2D layer as defined in the paper\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    input_channels -- integer, defining the number of input filters \n",
        "    expansion_rate -- integer, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the Gunn2D layer, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    output_channels = input_channels / expansion_rate\n",
        "    \n",
        "    for i in range(1, expansion_rate+1):\n",
        "      X_shortcut = X\n",
        "      print(X)\n",
        "      X = Conv2D(output_channels*2, (1, 1), strides = (1, 1), padding='valid', name = 'g1'+str(i))(X)\n",
        "      print(X)\n",
        "      X = BatchNormalization(axis = 3 , name = 'bn5')(X)\n",
        "      X = Activation('relu')(X)\n",
        "      X = Conv2D(output_channels*2, (3, 3), strides = (1, 1), padding='same', name = 'g2'+str(i))(X)\n",
        "      X = BatchNormalization(axis = 3 , name = 'bn6')(X)\n",
        "      X = Activation('relu')(X)\n",
        "      X = Conv2D(output_channels, (1, 1), strides = (1, 1), padding='valid', name = 'g3'+str(i))(X)\n",
        "      X = BatchNormalization(axis = 3 , name = 'bn7')(X)\n",
        "      print(X)\n",
        "      #Implementation of the identity block in Residual Network\n",
        "      X_shortcut = Conv2D(output_channels, (1, 1), strides = (1, 1), padding='valid', name = 'g1'+str(i))(X)\n",
        "      X_shortcut = BatchNormalization(axis = 3 , name = 'bn5')(X)\n",
        "      X = Add()([X , X_shortcut])\n",
        "\n",
        "    return X\n",
        "  \n",
        "def Gunn2D(X, input_channels, expansion_rate):  # lambda layer testing\n",
        "    X_shortcut = X\n",
        "    X = Add()([X , X_shortcut])\n",
        "    return X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWUQMRe13C85",
        "colab_type": "text"
      },
      "source": [
        "#  Convolutional Neural Networks - Forward and Backward pass\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0oBhPhr29pS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zero_pad(X, pad):\n",
        "    \"\"\"\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
        "    as illustrated in Figure 1.\n",
        "    \n",
        "    Argument:\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "    Returns:\n",
        "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant', constant_values = (0,0))\n",
        "    \n",
        "    return X_pad\n",
        "\n",
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    \"\"\"\n",
        "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
        "    of the previous layer.\n",
        "    \n",
        "    Arguments:\n",
        "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
        "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
        "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
        "    \n",
        "    Returns:\n",
        "    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
        "    \"\"\"\n",
        "\n",
        "    # Element-wise product between a_slice and W. Do not add the bias yet.\n",
        "    s = a_slice_prev * W   # element wise product in python\n",
        "    # Sum over all entries of the volume s.\n",
        "    Z = np.sum(s)\n",
        "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
        "    Z =  Z + float(b)\n",
        "\n",
        "    return Z\n",
        "\n",
        "\n",
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    print('Forward prop : {}'.format(A_prev.shape))\n",
        "    \n",
        "    # Retrieve dimensions from W's shape \n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    \n",
        "    # Retrieve information from \"hparameters\" \n",
        "    stride = hparameters[\"stride\"]\n",
        "    pad = hparameters[\"pad\"]\n",
        "    \n",
        "    # Compute the dimensions of the CONV output volume using the formula given above.\n",
        "    n_H = int((n_H_prev + 2*pad -f) // stride ) + 1\n",
        "    n_W = int((n_W_prev + 2*pad -f) // stride ) + 1\n",
        "    \n",
        "    print('Input Shape: {} {} {} {} '.format(m, n_H_prev, n_W_prev, n_C_prev, ))\n",
        "    print('Filter Shape: {} {} {} {} '.format(f, f, n_C_prev, n_C))\n",
        "    print('output Shape: {} {} {} {} '.format(n_H, n_W, stride, pad))\n",
        "    # Initialize the output volume Z with zeros. \n",
        "    #Z = np.zeros(( m, n_H, n_W, n_C ))\n",
        "    #Z = tf.zeros(( m, n_H, n_W, n_C ), tf.float32)\n",
        "    Z = tf.Variable(tf.zeros(( m, n_H, n_W, n_C ), tf.float32), validate_shape=False)\n",
        "    \n",
        "    # Create A_prev_pad by padding A_prev\n",
        "    A_prev_pad = zero_pad(A_prev,pad)\n",
        "\n",
        "    for i in range(m):                               # loop over the batch of training examples\n",
        "        a_prev_pad = A_prev_pad[i]                               # Select ith training example's padded activation\n",
        "        for h in range(n_H):                           # loop over vertical axis of the output volume    \n",
        "            for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\" \n",
        "                    vert_start = h*stride\n",
        "                    vert_end = vert_start+f\n",
        "                    horiz_start = w*stride\n",
        "                    horiz_end = horiz_start+f\n",
        "                    \n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad \n",
        "                    a_slice_prev = a_prev_pad[ vert_start:vert_end, horiz_start:horiz_end, : ]\n",
        "                    \n",
        "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. \n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[:,:,:,c], b[:,:,:,c])\n",
        "\n",
        "                                            \n",
        "    # Making sure your output shape is correct\n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def conv_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward(), output of conv_forward()\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),\n",
        "               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    dW -- gradient of the cost with respect to the weights of the conv layer (W)\n",
        "          numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    db -- gradient of the cost with respect to the biases of the conv layer (b)\n",
        "          numpy array of shape (1, 1, 1, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve information from \"cache\"\n",
        "    (A_prev, W, b, hparameters) = cache\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve dimensions from W's shape\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    \n",
        "    # Retrieve information from \"hparameters\"\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Retrieve dimensions from dZ's shape\n",
        "    (m, n_H, n_W, n_C) = dZ.shape\n",
        "    \n",
        "    # Initialize dA_prev, dW, db with the correct shapes\n",
        "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           \n",
        "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
        "    db = np.zeros((1, 1, 1, n_C))\n",
        "\n",
        "    # Pad A_prev and dA_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
        "    \n",
        "    for i in range(m):                       # loop over the training examples\n",
        "        \n",
        "        # select ith training example from A_prev_pad and dA_prev_pad\n",
        "        a_prev_pad = A_prev_pad[i, :]\n",
        "        da_prev_pad = dA_prev_pad[i, :]\n",
        "        \n",
        "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
        "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):           # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\"\n",
        "                    vert_start = h*stride\n",
        "                    vert_end = vert_start+f\n",
        "                    horiz_start = w*stride\n",
        "                    horiz_end = horiz_start+f\n",
        "                    \n",
        "                    # Use the corners to define the slice from a_prev_pad\n",
        "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "\n",
        "                    # Update gradients for the window and the filter's parameters \n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
        "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
        "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
        "                    \n",
        "        # Set the ith training example's dA_prev to the unpaded da_prev_pad : use X[pad:-pad, pad:-pad, :]\n",
        "        dA_prev[i, :, :, :] = dA_prev_pad[i, pad:-pad, pad:-pad, :]\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UiNYjPWCSgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A_prev = np.random.randn(10,4,4,3)\n",
        "#W = np.random.randn(2,2,3,8)\n",
        "#b = np.random.randn(1,1,1,8)\n",
        "#hparameters = {\"pad\" : 2,\n",
        "#               \"stride\": 2}\n",
        "\n",
        "#Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "#dA, dW, db = conv_backward(Z, cache_conv)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU9ms4ZcgpdA",
        "colab_type": "text"
      },
      "source": [
        "# Load pretrained VGG-16 for ImageNet in order to perform Transfer learning\n",
        "\n",
        "> Instead of random initializing we can initialize our model using weights of model learned for ImageNet and then further train our GUNN-15 model using random initialization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-wAyPvpujg1",
        "colab_type": "text"
      },
      "source": [
        "## Building GUNN-15 Model in Keras for 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYxmi_55mtym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GUNN_15_model(input_shape):\n",
        "    \"\"\"\n",
        "    Implementation of the GUNN-15 Model.\n",
        "    \n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    print(\"input_shape: {}\".format(input_shape))\n",
        "    X_input = Input(input_shape)\n",
        "    print(\"X_input: {}\".format(X_input.shape))\n",
        "    #frozen = VGG16 (weights=\"imagenet\", input_shape=(32,32,3), include_top=False)\n",
        "    #trainable = frozen.output\n",
        "    X = Conv2D(64, (3, 3), strides = (1, 1), padding='same', name = 'z1')(X_input) # 32x32x3 -> 32x32x64   ; padding = 1\n",
        "    X = BatchNormalization(axis = 3 , name = 'bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    convlayer = Conv2D(240, (1, 1), strides = (1, 1), padding='valid', name = 'z2')\n",
        "    X = convlayer(X) # 32x32x64 -> 32x32x240\n",
        "    #print(convlayer.get_weights())\n",
        "    layer = BatchNormalization(axis = 3 , name = 'bn2')\n",
        "    X = layer(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    #print(layer.get_weights())\n",
        "    #X = layer(X)\n",
        "    #print(layer.get_weights())\n",
        "    print(X)\n",
        "    weights = layer.get_weights()\n",
        "    gunnlayer = Gunn2D(240, 20) # custom Keras layer class\n",
        "    #print(gunnlayer.get_weights())\n",
        "    X = gunnlayer(X)\n",
        "    #print(gunnlayer.get_weights())\n",
        "    #X = Gunn2D(X, 240, 20, weights[:-1], weights[-1])\n",
        "    #X = Gunn2D(X, 240, 20, tf.convert_to_tensor(weights[:-1], dtype=tf.float32), tf.convert_to_tensor(weights[-1], dtype=tf.float32))\n",
        "    #X = Lambda(lambda X: Gunn2D(X, 240, 20, tf.convert_to_tensor(weights[:-1], dtype=tf.float32), tf.convert_to_tensor(weights[-1], dtype=tf.float32)))(X)\n",
        "    #X = Lambda(Gunn2D(X, 240, 20))(X)\n",
        "    print(X)\n",
        "    X = Conv2D(300, (1, 1), strides = (1, 1), padding='valid', name = 'z3')(X)\n",
        "    X = BatchNormalization(axis = 3 , name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = AveragePooling2D((2, 2), name = 'avg_pool1')(X)\n",
        "    print(X)\n",
        "    X = Lambda(lambda x: Gunn2D(X, 300, 25))(X)\n",
        "    print(X)\n",
        "    X = Conv2D(360, (1, 1), strides = (1, 1), padding='valid', name = 'z4')(X)\n",
        "    X = BatchNormalization(axis = 3 , name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = AveragePooling2D((2, 2), name = 'avg_pool2')(X)\n",
        "    print(X)\n",
        "    X = Lambda(lambda x: Gunn2D(X, 360, 30))(X)\n",
        "    print(X)\n",
        "    X = Conv2D(360, (1, 1), strides = (1, 1), padding='valid', name = 'z5')(X)\n",
        "    X = BatchNormalization(axis = 3 , name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = AveragePooling2D((8, 8), name = 'avg_pool3')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(360, activation='softmax', name = 'fc1')(X)\n",
        "    X = Dense(360, activation='softmax', name = 'fc2')(X)\n",
        "    X = Dense(10, activation='softmax', name = 'fc3')(X)\n",
        "\n",
        "    model = Model(inputs = X_input, outputs = X, name = 'GUNN-15-Model')\n",
        "    print(model)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16jkowTECbpJ",
        "colab_type": "text"
      },
      "source": [
        "## GUNN Layer implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByVHVGMT59Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Gunn2D(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_channels, expansion_rate):\n",
        "    super(Gunn2D, self).__init__()\n",
        "    self.input_channels = input_channels\n",
        "    self.expansion_rate = expansion_rate\n",
        "    self.hparameters = {\"pad\" : 0, \"stride\": 1}\n",
        "\n",
        "  def build(self, input_shape):\n",
        "      self.w = self.add_weight(shape=(1, 1, self.input_channels),\n",
        "                             initializer='random_normal',\n",
        "                             trainable=True)\n",
        "      self.b = self.add_weight(shape=(self.input_channels,),\n",
        "                             initializer='zeros',\n",
        "                             trainable=True)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    print('inputs')\n",
        "    print(inputs)\n",
        "    #(m, n_H_prev, n_W_prev, n_C_prev) = inputs.shape\n",
        "    inputs = Conv2D(240, (1, 1), strides = (1, 1), padding='valid', name = 'zGunn')(inputs)\n",
        "    #conv_forward(inputs, self.w, self.b, self.hparameters) # error: values not enough:  (f, f, n_C_prev, n_C) = W.shape\n",
        "    return inputs \n",
        "\n",
        "\n",
        "@tf.custom_gradient\n",
        "def Gunn2D_3(A_prev, input_channels, expansion_rate, W, b):\n",
        "    def grad(dZ):\n",
        "        print('backpropagation')\n",
        "        dA, dW, db  = conv_backward(dZ, cache)\n",
        "        return dA\n",
        "\n",
        "    print('custom_gradient : {},  weights: '.format(A_prev.shape, weights))\n",
        "    Z, cache = conv_forward(A_prev, W, b, hparameters)\n",
        "    Z = tf.cast(Z, 'float32')\n",
        "    return Z, grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I-9OEGBuLlS",
        "colab_type": "code",
        "outputId": "4284c560-43fc-42c4-db7f-e0faecdda7c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "# Create model\n",
        "#gunn15model = GUNN_15_model(X_train.shape) # input: (32, 32, 3)\n",
        "#print(X_train.shape) # (50000, 32, 32, 3)\n",
        "gunn15model = GUNN_15_model(X_train.shape[1:]) # input: (32, 32, 3)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (32, 32, 3)\n",
            "X_input: (None, 32, 32, 3)\n",
            "Tensor(\"activation_16/Relu:0\", shape=(None, 32, 32, 240), dtype=float32)\n",
            "inputs\n",
            "Tensor(\"activation_16/Relu:0\", shape=(None, 32, 32, 240), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a4ed7500b5e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgunn15model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGUNN_15_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# input: (32, 32, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-b0deee9bce73>\u001b[0m in \u001b[0;36mGUNN_15_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mgunnlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGunn2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# custom Keras layer class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#print(gunnlayer.get_weights())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgunnlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;31m#print(gunnlayer.get_weights())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#X = Gunn2D(X, 240, 20, weights[:-1], weights[-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    951\u001b[0m               \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             inputs, outputs = self._set_connectivity_metadata_(\n\u001b[0;32m--> 953\u001b[0;31m                 inputs, outputs, args, kwargs)\n\u001b[0m\u001b[1;32m    954\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_connectivity_metadata_\u001b[0;34m(self, inputs, outputs, args, kwargs)\u001b[0m\n\u001b[1;32m   2299\u001b[0m     \u001b[0;31m# This updates the layer history of the output tensor(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2300\u001b[0m     self._add_inbound_node(\n\u001b[0;32m-> 2301\u001b[0;31m         input_tensors=inputs, output_tensors=outputs, arguments=arguments)\n\u001b[0m\u001b[1;32m   2302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[0;34m(self, input_tensors, output_tensors, arguments)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \"\"\"\n\u001b[1;32m   2316\u001b[0m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0;32m-> 2317\u001b[0;31m                                         input_tensors)\n\u001b[0m\u001b[1;32m   2318\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n\u001b[1;32m   2319\u001b[0m                                       input_tensors)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   2314\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \"\"\"\n\u001b[0;32m-> 2316\u001b[0;31m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0m\u001b[1;32m   2317\u001b[0m                                         input_tensors)\n\u001b[1;32m   2318\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'layer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnfP6PNiuLvQ",
        "colab_type": "code",
        "outputId": "bfbbca1e-77d9-43dd-cc33-ec140f3bec81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(type(X_train.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "<class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3H3v4aiuL2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf9ZLDelpA69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3F2mNp2oHKY",
        "colab_type": "code",
        "outputId": "6e3e9d4f-c9df-425c-e147-2832b22d28fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp_pscxtuJ7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}